{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEPS:**  \n",
    "1. Convert data to correct images size\n",
    "2. Create TrainLoader instance\n",
    "3. Define model\n",
    "4. Define hyperparameters\n",
    "5. Train model\n",
    "5. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and transform it to correct input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_xy(df: pd.DataFrame) -> torch.IntTensor and torch.IntTensor:\n",
    "    \"\"\"Converts a Pandas DataFrame to 2 torch.IntTensor (x & y) so that you can later apply any function.\n",
    "    The df needs to have shape (N, 785) where N: number of samples and 785: target + 784 pixels (28x28)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The images data you will work with\n",
    "\n",
    "    Returns:\n",
    "        torch.IntTensor: x\n",
    "        torch.IntTensor: y\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_samples = df.shape[0]\n",
    "    X_train = None\n",
    "    y_train = None\n",
    "    \n",
    "    # get the labels\n",
    "    labels = df['label'].to_numpy()\n",
    "    y_train = torch.IntTensor(labels).reshape(number_of_samples, 1)\n",
    "\n",
    "    # convert the rest of dataframe to correct image size (28x28)\n",
    "    pixels = df[[col for col in df.columns if col != 'label']].to_numpy()\n",
    "    X_train = torch.IntTensor(pixels).reshape(number_of_samples, 1, 28, 28)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: torch.Size([42000, 1])\n",
      "X_train shape: torch.Size([42000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = convert_df_to_xy(df=df)\n",
    "\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot one image to see if it is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_to_plot = 756\n",
    "\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(X_train[image_to_plot][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46764ca8b7c597d72e34090c032f2809e12fa680ea97b2b9ad0d17deccea85ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
